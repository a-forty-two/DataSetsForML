{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12 NLP ",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPmlSRSKNEOlpkKW86ggEl7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/DataSetsForML/blob/master/12_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w66OkeQmom6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AGENDA FOR THE DAY \n",
        "# how exactly is NLP dictionaries and logic created?\n",
        "# REST of the week is dedicated to NLP\n",
        "# DataBricks -> Big Data -> how to access data using Apache Spark\n",
        "# PyTorch -> another dl framework besides TensorFlow, its ops are very much like NumPy\n",
        "# Dynamic Computing Graphs (ALSO A DAG, but better) in PyTorch rather than DAG\n",
        "# As a result, graphs build on-the-go (dynamically)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf7PyvOiqN0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LISTEN and SILENT -> both have same spelling but opposite meanings!\n",
        "# ASCII or UNICODE -> that would have been char by char encoding \n",
        "# WORDS are better "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7Hmzk09zW_o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "f6fa1846-54be-4c77-eae4-21af86393ff7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "sentences = ['I am a good boy', 'today is a beautiful day', 'good is beautiful', 'today is good', \"Today's milk is spoilt\", \"Spoilt, are you?\"]\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7mXiuo8ziWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myDict = Tokenizer(num_words=100)\n",
        "myDict.fit_on_texts(sentences) # LABEL ENCODING using FREQUENCY \n",
        "word_index = myDict.word_index\n",
        "data = {'beautiful dog! Is day yours?', \"milk is spoilt\"}\n",
        "text_encoded = myDict.texts_to_sequences(data)\n",
        "text_encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZBw6TBB0NUq",
        "colab_type": "code",
        "outputId": "be331162-901f-48ce-c854-c7812b2ef1d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 3,\n",
              " 'am': 8,\n",
              " 'are': 13,\n",
              " 'beautiful': 5,\n",
              " 'boy': 9,\n",
              " 'day': 10,\n",
              " 'good': 2,\n",
              " 'i': 7,\n",
              " 'is': 1,\n",
              " 'milk': 12,\n",
              " 'spoilt': 6,\n",
              " 'today': 4,\n",
              " \"today's\": 11,\n",
              " 'you': 14}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op4JIFK80O20",
        "colab_type": "code",
        "outputId": "240d5674-1d46-4f86-fac5-e3d72d78bdf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = {'beautiful dog! Is day yours?', \"milk is spoilt\"}\n",
        "text_encoded = myDict.texts_to_sequences(data)\n",
        "text_encoded"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[12, 1, 6], [5, 1, 10]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRxCA09Z2J89",
        "colab_type": "code",
        "outputId": "95ed5663-204d-4278-b246-68c6c7740dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# LOSING LENGTH OF DATA CAN CHANGE THE MEANING OF DATA!!! \n",
        "myDict = Tokenizer(num_words=100, oov_token='<UNK>') # OUT OF VOCABULARY TOKEN \n",
        "myDict.fit_on_texts(sentences) # LABEL ENCODING using FREQUENCY \n",
        "word_index = myDict.word_index\n",
        "data = {'beautiful dog! Is day yours?', \"milk is spoilt\"}\n",
        "text_encoded = myDict.texts_to_sequences(data)\n",
        "text_encoded\n",
        "# WORD SEQUENCES "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[13, 2, 7], [6, 1, 2, 11, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nogTQNlC3yy9",
        "colab_type": "code",
        "outputId": "87eae3d5-837c-4c3f-a4ee-20ac7c7b4515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "word_index"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 1,\n",
              " 'a': 4,\n",
              " 'am': 9,\n",
              " 'are': 14,\n",
              " 'beautiful': 6,\n",
              " 'boy': 10,\n",
              " 'day': 11,\n",
              " 'good': 3,\n",
              " 'i': 8,\n",
              " 'is': 2,\n",
              " 'milk': 13,\n",
              " 'spoilt': 7,\n",
              " 'today': 5,\n",
              " \"today's\": 12,\n",
              " 'you': 15}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKdv9-Qg31LP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "92b587b2-d475-4d64-a271-a1d6ce81ac27"
      },
      "source": [
        "# MAKE ALL SENTENCES EQUAL IN SIZE -> NORMALIZATION OF LENGTH -> PADDING\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "sequences = pad_sequences(text_encoded)\n",
        "sequences"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0, 13,  2,  7],\n",
              "       [ 6,  1,  2, 11,  1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWKXzRQU5Ixy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "56241e82-c373-433f-fa93-6b79188dbf0e"
      },
      "source": [
        "# MAKE ALL SENTENCES EQUAL IN SIZE -> NORMALIZATION OF LENGTH -> PADDING\n",
        "# SHOULD BE ON end for easier and optimized training \n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "sequences = pad_sequences(text_encoded, padding='post', maxlen=16, truncating='post') # truncating -> control how to del sentences\n",
        "sequences"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[13,  2,  7,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 6,  1,  2, 11,  1,  0,  0,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRvm95O45aFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c3d20f6f-17ca-42a1-ebe7-f7eaf400cf9d"
      },
      "source": [
        "# Embedding -> Global Average Pooling (Average sentiment) -> Pattern Detection\n",
        "# Embedding -> Global Average Pooling (Average sentiment) -> Dense(ReLU) -> Dense(Sigmoid)\n",
        "# Model 2\n",
        "# EVERY WORD its own sentiment -> Instead of average, just look up vectors from embdedding layer, flatten them,\n",
        "# detect pattern \n",
        "\n",
        "# Prev-> sentiment analysis of sentence\n",
        "# New -> sentiment analysis per word (WORD2WORD SEQUENCES)\n",
        "\n",
        "vocab_size = 100\n",
        "embed_dim = 16\n",
        "MAXLEN = 16\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "sequences = pad_sequences(text_encoded, padding='post', maxlen=MAXLEN, truncating='post')\n",
        "# 15,000 training samples -> imdb has \n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(100, 16, input_length=10))\n",
        "model.add(tf.keras.layers.Flatten()) # 16 vectors will be flattened to 1 dimension\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "model.summary()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 10, 16)            1600      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 160)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1610      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 3,221\n",
            "Trainable params: 3,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMblH2ob6f0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
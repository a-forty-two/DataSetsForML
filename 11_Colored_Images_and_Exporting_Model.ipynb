{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11 Colored Images and Exporting Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMrd18HCVzJcwRQZjqGg/A4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/a-forty-two/DataSetsForML/blob/master/11_Colored_Images_and_Exporting_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSdzOxwgu9pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # DIMENSION THAT YOU WANT TO HARDCODE FOR NN\n",
        " # Minimum dimension and filter size?\n",
        " # Hyperparameters\n",
        " # best dimensions to work with?\n",
        " # Image Size -> smaller than 32X32 for colored, 28X28 for grayscale will lose data upon compression\n",
        " # Colored Images -> 96,96 spread across 3 dimensions\n",
        " # Grayscale images -> 28,28 spread across 1 dimension\n",
        "\n",
        " # WHAT IS THE ORDER IN WHICH IMAGE IS COMING TO THE NETWORK?\n",
        " # (height,width,depth) -> depth is RGB, also DIMENSION \n",
        " # in NN we call depth as -> CHANNEL_DIMENSION\n",
        " # 2 popular channel dimensions are 1 and -1 \n",
        " # 1 means that depth is the 1st parameter -> (depth, height, width) -> (3,96,96) CHANNEL_FIRST\n",
        " # -1 means that depth is the last paramet -> (height, width, depth)   -> (96,96,3) CHANNEL_LAST\n",
        " # -1 -> TensorFlow, 1 -> Pytorch or theano\n",
        " \n",
        " # RESIZE IMAGE if they are not equal \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMxuZr2rd8dw",
        "colab_type": "code",
        "outputId": "b24654e2-4bb8-435b-cee9-c867d6d9f5d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# TABULAR DATA -> EXCEL, CSV, JSON, \n",
        "# there was always an output column -> y\n",
        "# rest of the columns/features were tested for their importance \n",
        "# select good features and learn on them\n",
        "# WE NEED TO BUILD OUR OWN DataFrames FOR IMAGES! \n",
        "\n",
        "# DUMMY DATASET -> 1000s of images can be using \n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAAVHRqmhAe7",
        "colab_type": "code",
        "outputId": "437babd5-fd1b-479d-c87a-c73902e045ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cartoon  sample_data  snek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b8Qwo_BhW_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9psQcHRHhEcE",
        "colab_type": "code",
        "outputId": "fd149a75-9932-4666-d859-64585f2c0f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# hyperparams\n",
        "!pwd # linux command to check the path where you are "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h3Vs9pphkfF",
        "colab_type": "code",
        "outputId": "4e37140d-919d-4f02-ec25-f76c34d9efe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls /content/data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cartoon  sample_data  snek\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzxMpAFqho-X",
        "colab_type": "code",
        "outputId": "ecb57ec7-974b-4a47-db89-925409818552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "path = '/content/data'\n",
        "IMAGE_DIMS = (224,224,3)\n",
        "data = [] # X, supposed to be read from folder \n",
        "labels = [] # Y\n",
        "import random\n",
        "from imutils import paths\n",
        "allImages = sorted(list(paths.list_images(path)))\n",
        "random.seed(42)\n",
        "random.shuffle(allImages)\n",
        "allImages"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/data/snek/000001.png',\n",
              " '/content/data/cartoon/000002.png',\n",
              " '/content/data/cartoon/000003.png',\n",
              " '/content/data/snek/000002.png',\n",
              " '/content/data/cartoon/000001.png']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cC3Hp8kUiwNh",
        "colab_type": "code",
        "outputId": "1b4196fc-b18e-4b0d-e7c8-628774f919a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# loop through allImages and create X and Y (input and output)\n",
        "import cv2\n",
        "from keras.preprocessing.image import img_to_array\n",
        "import os\n",
        "for imagePath in allImages:\n",
        "  img = cv2.imread(imagePath)\n",
        "  # images are off different size, RESIZE THEM ALL TO SAME SIZE\n",
        "  img = cv2.resize(img, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n",
        "  image = img_to_array(img)\n",
        "  data.append(image)\n",
        "  label = imagePath.split(os.path.sep)[-2] # SECOND LAST ELEMENT iN THE PATHNAME WAS THE CLASSNAME!!!\n",
        "  labels.append(label)\n",
        "  print(label)\n",
        "  print(imagePath)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "snek\n",
            "/content/data/snek/000001.png\n",
            "cartoon\n",
            "/content/data/cartoon/000002.png\n",
            "cartoon\n",
            "/content/data/cartoon/000003.png\n",
            "snek\n",
            "/content/data/snek/000002.png\n",
            "cartoon\n",
            "/content/data/cartoon/000001.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LDJnjdxk6wt",
        "colab_type": "code",
        "outputId": "611510fc-2ebb-4e0d-9b01-8025e670ea7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# NORMALIZE the data -> DIVIDE PIXELS by 255! largest pixel is 255! so all values will be \n",
        "# scaled between 0 and 1\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "data = np.array(data,dtype='float') / 255.0\n",
        "labels = np.array(labels)\n",
        "# OneHot, MultiHot, LabelEncoding, we only talked about LabelBinarizer \n",
        "# AnkleBoot, Tshirt, Coat -> LabelEncoding for output names!\n",
        "# LabelBinarizer converts your data into a 1-0 Matrix \n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels) # A type of ENCODING FOR OUTPUT \n",
        "labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_tUFbLCmdHI",
        "colab_type": "code",
        "outputId": "92a6380e-cbcf-48f1-db8b-443b947a7eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# SINCE ALL DATA IS READY, train_test_split \n",
        "from sklearn.model_selection import train_test_split\n",
        "trainx, testx, trainy, testy = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "len(testy)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO1tjkUSnGmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# IMAGE AUGMENTATION IS TAKEN CARE AT THIS STEP\n",
        "aug_fn = ImageDataGenerator(rotation_range=25,width_shift_range=0.1, height_shift_range=0.1, \n",
        "                            shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
        "# this is a TF TRANSFORMATION -> only RUN dynamically -> ONLY A LOGIC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1sCnhk9pzPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "HP_epochs = 100\n",
        "from keras.applications import VGG16\n",
        "model = VGG16()\n",
        "opt = Adam(lr=0.001, decay= 0.001/HP_epochs) # by the time learning is over, we want our LR ~ 0\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aRnZa0rrMMa",
        "colab_type": "code",
        "outputId": "c24edbfe-8053-4bb3-8fe9-455b940ceb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0RkuzY5sKyp",
        "colab_type": "code",
        "outputId": "a385b1e6-b4e4-4d20-bb9d-756b3bd8bd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "HP_batchSize = 32\n",
        "history = model.fit_generator(aug_fn.flow(trainx, trainy, batch_size=HP_batchSize),\n",
        "                              validation_data=(testx, testy), epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 14s 14s/step - loss: 8.0120 - acc: 0.0000e+00 - val_loss: 16.1182 - val_acc: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 11s 11s/step - loss: 8.0592 - acc: 0.5000 - val_loss: 1.0228e-04 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjxHKRx0tYmG",
        "colab_type": "code",
        "outputId": "bdce58eb-381f-4541-e38f-c359e94416be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 967
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMw5zYZCuv4b",
        "colab_type": "code",
        "outputId": "2b0585f5-0063-4aee-9980-de73e2ee3df8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTwRnJxq3dQP",
        "colab_type": "code",
        "outputId": "a14743c7-0b29-4ecc-e4fd-4660b8b002ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  jq1.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN-nWHwC3fPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing test image to be passed to model\n",
        "testImg = cv2.imread('/content/snek2.png')\n",
        "output = testImg.copy()# right practice, keep a copy safe\n",
        "\n",
        "# GO THRU THE SAME PROCESSING THAT YOU DID TO PREP THE IMAGE\n",
        "testImg = cv2.resize(testImg, (IMAGE_DIMS[0], IMAGE_DIMS[1]))\n",
        "testImg = testImg.astype('float')/255.0\n",
        "testImg = img_to_array(testImg)\n",
        "testImg = np.expand_dims(testImg, axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee-Z_C4N4crL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p = model.predict(testImg) # index of my classification\n",
        "idx = np.argmax(p)\n",
        "label = lb.classes_[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cicLEzVL4haL",
        "colab_type": "code",
        "outputId": "b7022e69-de7c-466a-f4ee-ac8bbc012843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cartoon'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "firSKJeZ4jQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We will build our own VGG model\n",
        "# It will be smaller, faster\n",
        "# TRAINING TIME WILL BE MUCH HIGHER -> >8-10 hours\n",
        "# HOMEWORK : BUILDING A DATASET\n",
        "# ANIMAL: 5 people in the team-> each building for 1 class\n",
        "# 250-300 images for each class\n",
        "# SUPERHERO : Batman, Superman, Shaktiman, SilverSurfer, SamuraiJack \n",
        "# 250-300 images for each of the class above\n",
        "# ANIMALS: Tiger, Lion, Chimp, Gorrilas, Langoors \n",
        "# 250-300 images for each of the class above \n",
        "# ONCE YOU HAVE COLLECTED IMAGES- they would need to be cleaned manually\n",
        "# - REPEATED IMAGES SHOULD BE DELETED\n",
        "# - your search results could contain noise/wrong images\n",
        "# PNG,JPEG, JPG, BMP, DAT -> use formats that are easily manipulatable \n",
        "# AWS S3=> upload all this sample data -> we can download it in GC or anywhere else\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqopZwGX7y4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('myRainyModel.h5') # EXPORT a model\n",
        "# TRANSFER LEARNING : ONLY EXPORT WEIGHTS\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or-O0Bt577ag",
        "colab_type": "code",
        "outputId": "ac08f966-ef12-405e-80d6-5c5647848209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# i could load this save model anywhere else using\n",
        "from tensorflow import keras\n",
        "model = keras.models.load_model('myRainyModel.h5')\n",
        "# if only weights were exported, create your own model of exactly SAME\n",
        "# shape as that of trained model, and load the weights \n",
        "# model= keras.Sequntial() # model.add(...)\n",
        "# model.load_weights('weights.pkl')\n",
        "# monday -> how to build an API out of exported model "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.training.Model at 0x7f27d1e432b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKPNgJIG80Da",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}